{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Propaganda:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,sentence,SUBJprop):\n",
    "        self.sentence = sentence\n",
    "        self.SUBJprop = SUBJprop\n",
    "        self.propaganda = self.get_propaganda()        \n",
    "\n",
    "    def get_propaganda(self):\n",
    "        if int(self.SUBJprop) <=3 :\n",
    "            return Propaganda.NEGATIVE\n",
    "        else:\n",
    "            return Propaganda.POSITIVE\n",
    "\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_sentence(self):\n",
    "        return [x.sentence for x  in self.reviews]\n",
    "\n",
    "    def get_propaganda(self):\n",
    "        return [x.propaganda for x in self.reviews]\n",
    "\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, self.reviews))\n",
    "        negative_shrunk = negative[:len(positive)]\n",
    "        self.reviews = positive + negative_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows:\n",
      "16774\n",
      "Total Positive:\n",
      "3780\n",
      "Total Negative:\n",
      "12994\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "reviews = []\n",
    "data  = pd.read_excel('Data/finalDataset.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(data.astype(str) , columns = ['Sentence','SUBJprop'])\n",
    "# iterate elements of attribute \"Sentence\" and \"SUBJprop\" and push to the array \"reviews\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    prop = row['SUBJprop']\n",
    "    reviews.append(Review(sentence,prop))\n",
    "\n",
    "\n",
    "print(\"Total Rows:\")\n",
    "print(len(reviews))\n",
    "print(\"Total Positive:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))))\n",
    "print(\"Total Negative:\")\n",
    "print(len(list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "punct = string.punctuation\n",
    "\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def text_data_cleaning(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            temp = token.lemma_.lower().strip()\n",
    "        else:\n",
    "            temp = token.lower_\n",
    "        tokens.append(temp)\n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords and token not in punct:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_cleaning(\"    Hello how are you. Like this video\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train:\n",
      "11741\n",
      "Positive:\n",
      "2646\n",
      "Negative:\n",
      "9095\n",
      "\n",
      "Total Development:\n",
      "2516\n",
      "Positive:\n",
      "567\n",
      "Negative:\n",
      "1949\n",
      "\n",
      "Total Test:\n",
      "2517\n",
      "Positive:\n",
      "567\n",
      "Negative:\n",
      "1950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "neg_prop = list(filter(lambda x: x.propaganda == Propaganda.NEGATIVE, reviews))\n",
    "pos_prop = list(filter(lambda x: x.propaganda == Propaganda.POSITIVE, reviews))\n",
    "\n",
    "########################################################################################\n",
    "#split trainig and DevTest dataset\n",
    "neg_train, neg_devtest  = train_test_split(neg_prop , train_size=0.7, random_state = 42 )\n",
    "pos_train, pos_devtest = train_test_split(pos_prop , train_size=0.7, random_state = 42 )\n",
    "########################################################################################\n",
    "#prepare training dataset\n",
    "train = neg_train + pos_train\n",
    "random.shuffle(train)\n",
    "########################################################################################\n",
    "#prepare development and test dataset\n",
    "neg_dev, neg_test = train_test_split(neg_devtest , train_size=0.5, random_state = 42 )\n",
    "pos_dev, pos_test = train_test_split(pos_devtest , train_size=0.5, random_state = 42 )\n",
    "\n",
    "dev = neg_dev + pos_dev\n",
    "random.shuffle(dev)\n",
    "\n",
    "test = neg_test + pos_test\n",
    "random.shuffle(test)\n",
    "########################################################################################\n",
    "print(\"Total Train:\")\n",
    "print(len(train))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_train))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_train))\n",
    "\n",
    "print(\"\\nTotal Development:\")\n",
    "print(len(dev))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_dev))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_dev))\n",
    "\n",
    "print(\"\\nTotal Test:\")\n",
    "print(len(test))\n",
    "print(\"Positive:\")\n",
    "print(len(pos_test))\n",
    "print(\"Negative:\")\n",
    "print(len(neg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after balance training dataset:\n",
      "5292\n",
      "Positive Propaganda:\n",
      "2646\n",
      "Negative Propaganda:\n",
      "2646\n"
     ]
    }
   ],
   "source": [
    "train_container = ReviewContainer(train)\n",
    "train_container.evenly_distribute()\n",
    "\n",
    "train_sentence = train_container.get_sentence()   \n",
    "train_propaganda = train_container.get_propaganda() \n",
    "\n",
    "development_sentence = [x.sentence for x in dev]\n",
    "development_propaganda = [x.propaganda for x in dev]\n",
    "\n",
    "test_sentence = [x.sentence for x in test]\n",
    "test_propaganda = [x.propaganda for x in test]\n",
    "\n",
    "print(\"Total rows after balance training dataset:\")\n",
    "print(len(train_sentence))\n",
    "\n",
    "print(\"Positive Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.POSITIVE))\n",
    "\n",
    "print(\"Negative Propaganda:\")\n",
    "print(train_propaganda.count(Propaganda.NEGATIVE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WordVectorTransformer(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self, model=\"en_core_web_sm\"):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        nlp = spacy.load(self.model)\n",
    "        return np.concatenate([nlp(doc).vector.reshape(1,-1) for doc in X])\n",
    "# class word2vec():\n",
    "#     def get_vec(self,x):\n",
    "#         train_x_vectors = []\n",
    "#         for x in train_sentence:\n",
    "#             train_x_vectors.append(nlp(x).vector)\n",
    "\n",
    "            # yield sparse2full(docvec, len(self.id2word))   \n",
    "# # Word2Vec\n",
    "# train_x_vectors = []\n",
    "# for x in train_sentence:\n",
    "#      train_x_vectors.append(get_vec(x))\n",
    "\n",
    "# word2vec = nlp(x).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])\n",
    "clf.fit(train_sentence,train_propaganda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('word2vec', WordVectorTransformer()), ('clf', LinearSVC())])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([('word2vec',WordVectorTransformer()), ('clf', classifier)])\n",
    "clf.fit(train_sentence,train_propaganda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.52      0.63      1949\n",
      "    POSITIVE       0.25      0.56      0.35       567\n",
      "\n",
      "    accuracy                           0.53      2516\n",
      "   macro avg       0.53      0.54      0.49      2516\n",
      "weighted avg       0.68      0.53      0.57      2516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(development_sentence)\n",
    "\n",
    "print(classification_report(development_propaganda, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8')",
   "name": "python382jvsc74a57bd0082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}